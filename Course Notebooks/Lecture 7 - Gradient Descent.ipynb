{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "\n",
    "The primary distinction of deep learning as opposed to many classical AI algorithms is that a computer learns a concept by observing lots of examples. The question at the heart of deep learning is \"How is the computer learning?\", which is the primary focus of this notebook. We will explain this learning process from a mathematical perspective by defining the learning algorithm along with some intuition behind why it works. \n",
    "\n",
    "The set up of this problem is that we have some training set $T=\\big\\{(x_1,y_1),\\ldots,(x_n,y_n)\\big\\}$ where $y_n$ is the label of the data point $x_n$. Our objective is to learn a function that can correctly classify each example in the training set and generalizes so new data points. In this case, our function is a neural network and we need to learn the set of weights so that it correctly labels the data points in our training set. The learning process is governed by minimizing a loss function whose value is determined by the number of classification mistakes made during the learning process and this function is defined with resepct to the weights in the network. Our goal is to find the set of weights that minimize the loss function, which implies that the network is correctly classifying the examples from the training set.\n",
    "\n",
    "Before we program gradient descent to train a neural network, let's start with some simpler examples and gain some intuition for how this algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def g(x):\n",
    "    return x**4+x**3+2*x**2+2*x,\n",
    "\n",
    "def deriv_g(x):\n",
    "    return True\n",
    "\n",
    "# Plot function \n",
    "x = np.arange(-10,10,0.1)\n",
    "## make plot ##\n",
    "\n",
    "\n",
    "# Gradient descent\n",
    "max_iter = True # you choose\n",
    "epsilon  = True # you choose\n",
    "x        = True # choose starting point\n",
    "iter     = 0\n",
    "conv     = False\n",
    "while iter<max_iter or ~conv:\n",
    "    # update x\n",
    "    # plot x\n",
    "    # check for convergence\n",
    "    iter += 1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
